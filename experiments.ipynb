{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3hEfbuKdMGD"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/pr-Mais/mm_sentiment_analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd mm_sentiment_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3_x0IAQ4iMv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "%matplotlib inline\n",
        "# pd.set_option('precision', 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!wget -O data/reviews_makkah_raw.csv \"..\"\n",
        "!wget -O data/reviews_medina_raw.csv \"..\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCQnDJkugCWe"
      },
      "source": [
        "# Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgtAJC8TPULr"
      },
      "outputs": [],
      "source": [
        "makkah_reviews_path = './data/reviews_makkah_raw.csv'\n",
        "medina_reviews_path = './data/reviews_medina_raw.csv'\n",
        "\n",
        "paths = [makkah_reviews_path, medina_reviews_path]\n",
        "\n",
        "import src.data as data\n",
        "\n",
        "df = data.import_data(paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQHQSQy9WuZU",
        "outputId": "cbd83d2b-d1a4-4ae5-d2ef-c6087a25ac86"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDo-jSusVXdm"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "This step will prepare the data set by exploring it, applying normalization where needed, and missing and duplicate value checking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_HKOpITV2Z7"
      },
      "source": [
        "The data has been scraped from **booking.com** for English hotel reviews written during the period prior to and post COVID pendamic, for visitors of Madinah and Makkah."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GcahYkKCZn5r"
      },
      "source": [
        "## Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.check_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "wwgUnFqoVXJs",
        "outputId": "7f3f1433-ed09-407c-a42c-0f0014db282d"
      },
      "outputs": [],
      "source": [
        "# some keys in the data\n",
        "negative_key = 'review_negative'\n",
        "positive_key = 'review_positive'\n",
        "date_key = 'date_reviewed'\n",
        "\n",
        "df = data.prepare_data(df, positive_key, negative_key, date_key)\n",
        "\n",
        "# TODO answer the question: what does NaN represents in this dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = data.clean_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uye3LAS3ThLZ"
      },
      "source": [
        "TODO clean number & duplicate reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rnUccR652_Z"
      },
      "source": [
        "# Making features ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = data.encode_labels(df)\n",
        "\n",
        "# 1 = positive, 0 = negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.target == 1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.target == 0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdllk7Rd5rda"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Due to unbalance between positive and negatvie reviews, \n",
        "# we take 15% of positive reviews to balance it with negative.\n",
        "reviews_pos = df[df.target == 1].sample(frac=0.12)\n",
        "reviews_neg = df[df.target == 0]\n",
        "df = pd.concat([reviews_pos, reviews_neg]).sample(frac=1)\n",
        "\n",
        "# Assign features and targets\n",
        "features = df.review.to_numpy()\n",
        "target = df.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_neg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_pos.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQiP9TwD6_6T"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, stratify=target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8hR3wxfR5Uv",
        "outputId": "aab3e672-aae8-469b-f937-ffd1b3ac0ca3"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SolGumSnSC7e"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVjayd3mOMHJ"
      },
      "outputs": [],
      "source": [
        "# Testing with 2-gram and 3-gram tokens.\n",
        "ngram_range = (1, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-qNJldncUOY"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer(analyzer='word', ngram_range=ngram_range)\n",
        "\n",
        "# Calculating n-grams for features & labels.\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "train_features = (count_vect.get_feature_names_out())\n",
        "\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "test_features = (count_vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-2cM-upJeTO_",
        "outputId": "81722861-b34b-4836-9c9c-a86cc5e82086"
      },
      "outputs": [],
      "source": [
        "# Checking how it looks like\n",
        "pd.DataFrame(train_features, columns=['gram'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S-y3KVCjFWMe",
        "outputId": "3417ae25-ae97-4694-b9d2-eb22b4a4dc27"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(test_features, columns=['gram'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXOVxaB0V-ae",
        "outputId": "c4c3bcc7-eb1b-4316-9062-3be1d6836be5"
      },
      "outputs": [],
      "source": [
        "X_train_counts.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1zxZod0-W1fs"
      },
      "source": [
        "## TF-IDF Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg2mt3OCe2VD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize_data(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "def visualize_features(tf_idf: np.ndarray, feats: np.ndarray):\n",
        "  # Getting top ranking features\n",
        "  sums = tf_idf.sum(axis = 0)\n",
        "\n",
        "  data = []\n",
        "  gram = 0\n",
        "\n",
        "  for col, term in enumerate(feats):\n",
        "      if gram == 0:\n",
        "        gram = 'bigram' if len(term.split(' ')) == 2 else 'trigram'\n",
        "      data.append((term, sums[0, col]))\n",
        "      \n",
        "  ranking = pd.DataFrame(data, columns = [gram, 'rank'])\n",
        "  ranking['rank'] = normalize_data(ranking['rank'])\n",
        "  words = (ranking.sort_values('rank', ascending = False))\n",
        "\n",
        "  display(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF_1B8uKc5EL"
      },
      "outputs": [],
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts, y_train)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WaN8Y9Vgn1QZ",
        "outputId": "35e87a0b-265a-41db-c328-160792863ee9"
      },
      "outputs": [],
      "source": [
        "visualize_features(X_train_tfidf, train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAoDJCo9dNWQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def train_cv(X, y, classifier, param_grid, folds):\n",
        "  grid = GridSearchCV(classifier, param_grid, cv=folds, scoring='accuracy', return_train_score=False, verbose=1)\n",
        "  grid_search = grid.fit(X, y)\n",
        "\n",
        "  print(grid_search.best_params_)\n",
        "  print(grid_search.best_score_)\n",
        "\n",
        "  return grid_search.best_params_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u2xiM2iplQxF"
      },
      "source": [
        "## kNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFZGiIUbdkEm",
        "outputId": "adf0bd33-d67c-438d-d6fe-d0f288ef2da9"
      },
      "outputs": [],
      "source": [
        "k_range = list(range(1, 31))\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "classifier = KNeighborsClassifier(n_jobs=-1)\n",
        "k = train_cv(X_train_tfidf, y_train, classifier, param_grid, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSYLxIBRP1NH"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=k['n_neighbors'])\n",
        "knn.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft5THrr6UF0E"
      },
      "outputs": [],
      "source": [
        "y_pred = knn.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1tCA4tFXWsv"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "matrix_df = pd.DataFrame(confusion_matrix)\n",
        "labelsStr = ['negative', 'positive']\n",
        "\n",
        "ax = plt.axes()\n",
        "sns.set(font_scale=1.3)\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"crest\", linewidth=2)\n",
        "\n",
        "ax.set_title('Confusion Matrix - Decision Tree')\n",
        "ax.set_xlabel(\"Predicted\", fontsize =15)\n",
        "ax.set_xticklabels(labelsStr)\n",
        "ax.set_ylabel(\"Actual\", fontsize=15)\n",
        "ax.set_yticklabels(list(labelsStr), rotation = 0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW9pmotNRv1v"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXgqtxsy0tJP"
      },
      "outputs": [],
      "source": [
        "test_sentiment = pd.DataFrame([], columns=['Review', 'Sentiment'])\n",
        "\n",
        "for i in np.random.choice(X_test_tfidf.shape[0], 10, replace=False):\n",
        "  sentiment = 'negative' if knn.predict(X_test_tfidf)[i] == 0 else 'positive'\n",
        "  test_sentiment.loc[i] = [X_test[i], sentiment]\n",
        "\n",
        "display(test_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS5phI3YF6Bu"
      },
      "outputs": [],
      "source": [
        "test_sentiment.to_csv('test_sample.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0p4UBAcELKmr"
      },
      "source": [
        "## RF Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqJTxT2KF9X_"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "param_grid = dict(n_estimators=[1000])\n",
        "classifier = RandomForestRegressor(n_jobs=-1)\n",
        "classifier.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy0Wa-FDO7lg"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7ck-39xUGFi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-hrAMtIpSvm"
      },
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF9DeoGldmwh"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWTI9JiEpU6Y",
        "outputId": "1ba85f61-d3a9-47bc-c108-41ce4dc5f9fe"
      },
      "outputs": [],
      "source": [
        "from src import utils\n",
        "from src import experiment\n",
        "\n",
        "utils.check_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AM0GoPBggG-"
      },
      "outputs": [],
      "source": [
        "# First experiment with BERT\n",
        "bert = experiment.TransformerExperiment(name='BERT',\n",
        "                                        tokenizer=BertTokenizer.from_pretrained(\n",
        "                                            'bert-base-uncased', do_lower_case=True),\n",
        "                                        model=BertForSequenceClassification.from_pretrained(\n",
        "                                            \"bert-base-uncased\",\n",
        "                                            num_labels=2,\n",
        "                                            output_attentions=False,\n",
        "                                            output_hidden_states=False,\n",
        "                                        ),\n",
        "                                        X=X_train,\n",
        "                                        y=y_train,\n",
        "                                        batch_size=32,\n",
        "                                        epochs=4)\n",
        "\n",
        "# Second experiment with RoBERTa\n",
        "roberta = experiment.TransformerExperiment(name='RoBERTa',\n",
        "                                           tokenizer=RobertaTokenizer.from_pretrained(\n",
        "                                               'roberta-base', do_lower_case=True),\n",
        "                                           model=RobertaForSequenceClassification.from_pretrained(\n",
        "                                               'cardiffnlp/twitter-roberta-base-emotion',\n",
        "                                               num_labels=2,\n",
        "                                               output_attentions=False,\n",
        "                                               output_hidden_states=False,\n",
        "                                           ),\n",
        "                                           X=X_train,\n",
        "                                           y=y_train,\n",
        "                                           batch_size=32,\n",
        "                                           epochs=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bert.tokenize()\n",
        "bert.create_dataset()\n",
        "bert.train()\n",
        "bert.print_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roberta.tokenize(max_len=512)\n",
        "roberta.create_dataset()\n",
        "roberta.train()\n",
        "roberta.print_stats()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-3hEfbuKdMGD",
        "uCQnDJkugCWe",
        "QDo-jSusVXdm",
        "-rnUccR652_Z",
        "u2xiM2iplQxF",
        "0p4UBAcELKmr"
      ],
      "provenance": []
    },
    "datalore": {
      "base_environment": "default",
      "computation_mode": "JUPYTER",
      "package_manager": "pip",
      "packages": [
        {
          "name": "nltk",
          "source": "PIP",
          "version": "3.7"
        },
        {
          "name": "num2words",
          "source": "PIP",
          "version": "0.5.12"
        }
      ],
      "version": 1
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
